> https://www.bilibili.com/video/av3781284 缪柏其教授
> http://staff.ustc.edu.cn/~zwp/teach/Prob-Stat/probstat.htm 讲义
> https://www.youtube.com/watch?v=Ss8do4zlaAc&list=PL_fXnA_vUjgPL9zDO_fRpHVhdqqyO13hH&index=18&t=0s 参考

## ch1 随机事件与概率

* 概率模型是对随机现象的一种数学描述：它由样本空间和样本空间上的概率构成
* ![image](https://user-images.githubusercontent.com/8290205/55150215-a65b9c80-5186-11e9-803d-f64a85620a0a.png)

* 样本空间是一个集合，其元素描述了我们刚兴趣的实验结果
* 样本空间的任何一个子集都被称为一个事件。如果一个子集只有一个元素，那这个子集被称为基本事件
* 若事件 A, B 不可能在同一次实验中同时发生，则 A, B 是互斥的，AB = φ
* P(Ω) = 1 => 实验结果总是样本空间的一个元素
* 若 A, B 互斥 => P(A U B) = P(A) + P(B) => 概率函数的可加性
* 古典概型算概率本质就是数数(乘法原理 & 加法原理)
* 有趣的随机现象：50 个人生日生日都不相同的概率为 97% => 相遇的概率比预期要大的多！
* 仔细考虑样本空间
* 提供的信息=条件 => 条件概率
* 公理3 => 全概率公式
* 贝叶斯公式 => 因果关系互换
* P(A|B) * P(B) = P(B|A) * P(A)
* 全概公式 => 求复杂概率转化为：不同情况下发生简单事件概率的求和问题
* P (A) = P (A|B)P(B) + P (A|B^)P(B^)
* 独立性 P(AB) = P(A)*P(B)
    * P(ABC) = P(A)P(B)P(C)
    * P(AB) = P(A)*P(B)
    * P(AC) = P(A)*P(C)
    * P(BC) = P(B)*P(C)
* 独立性: 对于事件 A, B 有 P(AB) = P(A)*P(B) (从概率角度)
* 互斥性: 对于事件 A, B 有 A∩B=φ (从集合角度)

## ch2 随机变量及其分布

* 在很多实验中，处理一个汇总的变量比处理概率结构要方便的多
* 随机变量：取值由概率而定的变量
* 分布律(离散型的一种表示方法)
* 分布函数 F(x) = P(X <= x)
* 密度函数 ∫ f(x)dx = 1
* 分布是了解随机现象的最高境界

* 离散型: 二项分布
    * X ~ B(n, p)
    * 小概率事件在试验次数足够多时必然发生(命中率低的人打靶)
* 离散型: 泊松分布
    * 机器出现的故障数, 自然灾害发生的次数，DNA序列的变异数(描述单位时间内随机事件发生的次数的概率分布)
    * X ~ Poisson(λ) // λ=n*p
    * 二项分布在一定条件下可以用泊松分布近似代替(非常接近)
        * n > 30
        * n*p <= 5 (n 较大，p 很小)
* 连续型: 指数分布
    * 旅客进入机场的时间间隔、打进客服中心电话的时间间隔(独立随机事件发生的时间间隔)
    * X ~ exp(λ)
    * 无后效性 P(X > t+s | X > t) = P(X > s)
* 连续型: 正态分布
    * 反映大量因素叠加的概率分布(https://www.shuxuele.com/data/quincunx.html)
    * X ~ normal(μ, σ^2)
    * f(x) 关于 x=μ 对称
    * σ 越小, f(x) 峰越陡峭, σ 越大, f(x) 峰越平缓
    * 3σ 原则 => 0.9974 
    * 若 X ~ normal(μ, σ^2) <=> (Y = (X - μ)/σ) ~ normal(0, 1)
* 随机向量 (多种因素决定概率)
* 边际分布律不能决定联合分布律
* 条件分布 
    * P(X = x0 | Y = y0) = P(X=x0, Y=y0) / P(Y=y0)
    * f(x|y) = f(x, y) / fy(y)
* 随机变量的独立性
    * P(X=x0, Y=y0) = P(X=x0)*P(Y=y0)
    * f(x, y) = fx(x) * fy(y)
    * 二元正态随机变量相互独立的充要条件是 ρ=0
* 随机变量的函数分布
    * 怎么理解： H 为身高(米)，W 为体重(千克)， 已知 H 的分布，W 的分布，求 BMI 指数的分布 BMI = W / (H^2)
    * 设 X ~ B(n, p), Y ~ B(m, p) => X + Y ~ B(n+m, p) 这种性质称为再生性
    * 设 X ~ Normal(μ1, σ1^2), Y ~ Normal(μ2, σ2^2) => X + Y ~ Normal(μ1 + μ2, σ1^2 + σ2^2)
    * X, Y 独立 => Z = X+Y => fz(z) = ∫ fx(x)fy(z-x)dx (卷积公式)



## ch3 随机变量的数字特征

* E(X) = ∫ xf(x)dx (数学期望不一定存在)
* 数学性质 
    * E(const) = const
    * E(aX+b) = aE(X) + E(b)
    * E(g(X)) = ∫ g(x)f(x)dx
    * E(XY) = E(X)*E(Y) 当 X, Y 独立时
* 条件期望 E(X|Y=y0) = ∫ xf(x|y=y0)dx
* https://www.shuxuele.com/data/standard-deviation.html#WhySquare
* μ = E(X), 方差定义: E((X-μ)^2) = E(X^2) - (E(X))^2
    * Var(X) >= 0
    * Var(c)=0
    * Var(aX+b) = (a^2)*Var(X)
    * X, Y 独立时 Var(X + Y) = Var(X) + Var(Y)
    * 当数据比较分散时，标准差也比较大
    * 差的意思是离正常有多远
* 泊松分布方差 λ
* 二项分布方差 np(1-p)
* 正态分布方差 σ^2
* 设 μ=E(X), σ^2 = Var(X) 称 ξ = (X - μ)/σ 为标准化随机变量
    * 引入标准化随机变量是为了解决量纲问题
    * 考察人的身高, 以米为单位得到 X1，以厘米为单位得到 X2，显然 100*X1 = X2
    * 把 X1, X2 标准化 ξ1, ξ2 显然  ξ1=ξ2 
    * 标准化随机变量使得问题易于处理
    * E(ξ) = 0
    * Var(ξ) = 1
    * 标准分数(Standard Score)又称 Z 值, Z 值是从感兴趣的点到均值之间有多少个标准差
* 马尔可夫不等式 P(X >= a) <= μ/a
    * 利用期望，估计概率的上界
    * 不超过1/5的人口会有超过5倍于人均收入的收入
* 切比雪夫不等式 P(|X - μ|>=kσ) <= 1/k^2
    * 利用标准差，估计概率上界
    * 与平均相差2个标准差以上的值，数目不多于1/4
    * 切比雪夫不等式预测的准确率要远远高于马尔科夫不等式(因为切比雪夫用到了方差)
* 相关系数是衡量随机变量间的线性关系的 |ρ|<=1

## ch4 大数定律 & 中心极限定理
* 大数律是描述相当多次数重复实验的结果: 样本数量越多，则其算术平均值就有越高的概率接近期望值
* 大数定律指出，当 n -> ∞ 时，样本均值 X-bar -> μ
* 大数定律指出，当 n -> ∞ 时，X-bar 是一个变化非常小的随机变量
* 大数定律指出，当 n 比较大时，可以用 X-bar 代替总体的真实均值：即均值估计
* 大数定律指出，X-bar 以概率收敛(数列才有收敛的说法)到 E(X-bar)，在大样本的情况下，随机变量最终收敛到一个数
* Xi 为 iid(E(Xi)=μ, Var(Xi)=σ^2)，X = X1 + X2 + ... + Xn => n -> ∞ P( (X - nμ)/(σ*√n) <= x ) -> Normal(0, 1)
* Xi 为 iid(E(Xi)=μ, Var(Xi)=σ^2)，X = X1 + X2 + ... + Xn => n -> ∞ P( (X-bar - μ)/(σ/√n) <= x ) -> Normal(0, 1)
* 中心极限定理指出，X-bar -> μ 的过程中，以多大的速度趋近，这个速度的量级是 O(1/√n)
* 中心极限定理指出，参数为n, p的二项分布以np为均值、np(1-p)为方差的正态分布为极限
* 中央极限定理解释了高密顿板小球累积高度曲线为什么是正态分布独有的钟形曲线
* 中心极限定理说明，大量相互独立随机变量的和收敛于正态分布(这组定理是数理统计学和误差分析的理论基础)

# 统计基本概念

* 统计是一门艺术(人为的)
* 统计推断要综合，样本容量，数据质量，置信度
* 描述性统计(传统统计：比例，中位数，折线图)
* 数理统计(以概率论为工具：研究如何有效收集随性的数据，如何分析数据，给定模型下进行统计推断)
    * 抽样(一门课程)
    * 实验(一门课程)
    * 统计方法
    * 估计(estimate) => [点估计, 区间估计]
    * 检验(test) => [参数检验, 非参数检验]
* 总体(population): 研究对象的全体(某一指标的取值，取值的概率) => 可视为某个随机变量的分布
* 抽样(sample): 从总体中按一定的规则(随机抽样)抽取的一些个体(x1, x2, ... , xn) 称 n 为样本容量
    * 有放回抽样 (x1, x2, ..., xn) 为 iid，其中 xi 的分布与总体分布一样
    * 无放回抽样 (当总体很大，样本容量较大时，无放回抽样近似于有放回抽样)
    * 样本在抽签之前视为随机变量，抽签之后视为一组数
* 统计量：为了刻画某个特征，对样本的一种加工(本质上就是随机变量的函数)
    * 样本均值：X-bar = 1/n * ∑Xi
    * 样本方差：S^2 = 1/(n-1) * ∑(Xi - X-bar)^2
    * 统计量是一个确定的数
* (X-bar - μ) / (S/√n) ~ t(n-1) 自由度为 n-1 的 t 分布
* 点估计
    * 矩方法(用样本矩代替总体矩(大数定律)) 
        * X-bar ~ E(X)
        * S^2 ~ Var(X)
        * θ-hat 是统计量
        * 估计不唯一
    * 极大似然估计
        * X ~ f(x)(θ)
        * L(X|θ) = ∏f(xi|θ) 给定 xi，称 L 作为 θ 的似然函数
        * 已知 (x1, x2, x3, ...) ，尝试不同的 θ，使得 L(X|θ) 最大
        * L(X|θ) 的意义就是实验结果的概率，概率越大的，那么这个假设的参数就越可能是真的
        * https://www.zhihu.com/question/24124998
        * 越多的实验结果，让参数越来越明确
        * 极大似然估计比矩估计更准确
* 估计量的评价标准
    * 无偏性：设 θ-hat = 统计量(x1, x2, x3), 称 E(θ-hat) = θ 为 θ 的无偏估计量，E(θ-hat - θ) 称为偏差(误差)
        * https://baike.baidu.com/item/%E5%8E%9F%E7%82%B9%E7%9F%A9
        * https://bkso.baidu.com/item/%E6%A0%B7%E6%9C%AC%E7%9F%A9
        * 用样本矩估计总体矩是无偏的 (每个样本和总体的分布一样)
        * S^2 = 1/(n-1) * ∑(Xi - X-bar)^2 是无偏估计
        * 无偏估计反映了统计量只有随机误差而没有系统误差
    * 最小方差无偏估计：对于所有无偏估计中，拥有最小方差的无偏估计 Var(θ-hat)
* 区间估计
* 假设检验
    * H0 和 H1 地位不平等，我们是站在保护 H0 的立场上。因此在没有充分的证据下，我们总认为 H0 
    * 接受 H0，不能说明 H0 一定正确，只能说到目前为止没有足够的证据说 H0 不对，所以接受 H0
    * 拒绝 H0，意味着有充分的证据说明 H0 不对。
    * 原则1: 久经考验的放在 H0
    * 原则2: 把你需要的结论放在 H1
    * 两个正态分布均值差的检验
    * 两样本方差比的检验  
* 拟合优度检验(test of goodness of fitting)
    * p-value 拟合优度

## 概率八种分布
* 0-1 分布
* 二项分布
* 离散型等待分布
* 泊松分布
* 泊松分布
* 正态分布
* 指数分布(连续型等待分布)

## chx 同花顺概率模型

- 从一副牌中抽取5张牌共有 2598960 中情况
- 对子: (13 * combntns(4, 2)) * (combntns(12, 3) * 4 * 4 * 4)/2598960 = 42.2%
- 两对: (combntns(13, 2) * combntns(4, 2) * combntns(4, 2)) * 44/2598960 = 4.7% (低概率事件)
- 三条: (13 * combntns(4, 3)) * (combntns(12, 2) * 4 * 4)/2598960 = 2.1%
- 顺子: (40 * 4 * 4 * 4 * 4 - 10 * 4)/2598960 = 0.39%
- 同花: (combntns(13, 5) * 4 - 10 *4)/2598960 = 0.19%
- 葫芦: (13 * combntns(4, 3)) * (12 * combntns(4, 2))/2598960 = 0.14%
- 四条: 13 * 12 * 4/2598960 = 0.024%
- 同花顺: (40 - 4)/2598960 = 0.0013%

## chy 多元微积分补充

- 可微的本质意义：以直代曲
- 梯度是一个向量，可微函数 f(x, y) => gradf = [∂f/∂x, ∂f/∂y]
- 梯度方向是下降/上升最快的方向
- 不定积分: ∫ dy = y + C
- 分部积分: uv = ∫uv' + ∫u'v